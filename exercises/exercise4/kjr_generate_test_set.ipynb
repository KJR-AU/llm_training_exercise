{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Test Set with TruLens\n",
    "\n",
    "In the early stages of developing an LLM app, it is often challenging to generate a comprehensive test set on which to evaluate your app.\n",
    "\n",
    "This notebook demonstrates the usage of test set generation using TruLens, particularly targeted at applications that leverage private data or context such as RAGs.\n",
    "\n",
    "By providing your LLM app callable, we can leverage your app to generate its own test set dependant on your specifications for `test_breadth` and `test_depth`. The resulting test set will both question categories tailored to your data, and a list of test prompts for each category. You can specify both the number of categories (`test_breadth`) and number of prompts for each category (`test_depth`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.generate_test_set import GenerateTestSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Imports from LangChain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import json\n",
    "#import sqlite3\n",
    "#print (\"SQLite Version is:\", sqlite3.sqlite_version)\n",
    "#print (\"DB-API Version is:\", sqlite3.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load example content from the web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm_training_exercise/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm_training_exercise/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"KJR-Policy-Manual-August-23.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "vectorstore = Chroma.from_documents(documents=pages, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm_training_exercise/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a test set using the RAG\n",
    "\n",
    "Now that we've set up the application, we can instantiate the `GenerateTestSet` class with the application. This way the test set generation will be tailored to your app and data.\n",
    "\n",
    "After instantiating the `GenerateTestSet` class, generate your test set by specifying `test_breadth` and `test_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Environmental Impact Policy': ['How does KJR aim to minimize the environmental impact of its operations according to its Environmental Impact Policy?',\n",
       "  'What steps does KJR take to ensure compliance with relevant environmental legislation and regulations in its operations?'],\n",
       " 'Modern Slavery Policy': ['How does KJR ensure compliance with the Modern Slavery Act in its business operations and relationships?',\n",
       "  \"What are the key elements of KJR's Modern Slavery program to prevent, detect, and respond to the risk of Modern Slavery occurring within the organization or in any other business relationships?\"],\n",
       " 'Code of Conduct': ['What are the consequences for breaching the Code of Conduct at KJR?',\n",
       "  'How does KJR define bribery and corruption in their Anti-Bribery and Corruption Policy?'],\n",
       " 'Policy Manual': ['What is the purpose of the KJR Policy Manual?',\n",
       "  'How many pages are in the KJR Policy Manual?'],\n",
       " 'Workplace Standards': ['What are the dress standards expected of KJR team members when working on-site or meeting with customers?',\n",
       "  'What are the eligibility criteria for team members to request flexible working arrangements at KJR?']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = GenerateTestSet(app_callable = rag_chain.invoke)\n",
    "test_set = test.generate_test_set(test_breadth = 5, test_depth = 2)\n",
    "test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental Impact Policy\n",
      "Modern Slavery Policy\n",
      "Code of Conduct\n",
      "Policy Manual\n",
      "Workplace Standards\n"
     ]
    }
   ],
   "source": [
    "for category in test_set:\n",
    "        print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Environmental Impact Policy\": [\n",
      "        \"How does KJR aim to minimize the environmental impact of its operations according to its Environmental Impact Policy?\",\n",
      "        \"What steps does KJR take to ensure compliance with relevant environmental legislation and regulations in its operations?\"\n",
      "    ],\n",
      "    \"Modern Slavery Policy\": [\n",
      "        \"How does KJR ensure compliance with the Modern Slavery Act in its business operations and relationships?\",\n",
      "        \"What are the key elements of KJR's Modern Slavery program to prevent, detect, and respond to the risk of Modern Slavery occurring within the organization or in any other business relationships?\"\n",
      "    ],\n",
      "    \"Code of Conduct\": [\n",
      "        \"What are the consequences for breaching the Code of Conduct at KJR?\",\n",
      "        \"How does KJR define bribery and corruption in their Anti-Bribery and Corruption Policy?\"\n",
      "    ],\n",
      "    \"Policy Manual\": [\n",
      "        \"What is the purpose of the KJR Policy Manual?\",\n",
      "        \"How many pages are in the KJR Policy Manual?\"\n",
      "    ],\n",
      "    \"Workplace Standards\": [\n",
      "        \"What are the dress standards expected of KJR team members when working on-site or meeting with customers?\",\n",
      "        \"What are the eligibility criteria for team members to request flexible working arrangements at KJR?\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(test_set, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"generated_prompts\"\n",
    "groundtruth_prompts = []\n",
    "for category in test_set:\n",
    "    for i in test_set[category]:\n",
    "        string = '{\"input\": \"' + i + '\", \"expected_output\": null}'\n",
    "        new_data = json.loads(string)\n",
    "        groundtruth_prompts.append(new_data)\n",
    "\n",
    "with open(filename + '.json', \"w\") as outfile:\n",
    "    outfile.write(json.dumps(groundtruth_prompts, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide a list of examples to help guide our app to the types of questions we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Professionalism': ['How many days of annual leave do KJR team members accrue per completed year of service?',\n",
       "  'What is the basic entitlement for personal leave for full-time KJR team members?'],\n",
       " 'confidentiality': ['What are the consequences for excessive absenteeism or tardiness at KJR?',\n",
       "  'Is it possible for a complainant or witness to remain anonymous in a complaint or investigation at KJR?'],\n",
       " 'social media': ['How many hours are KJR employees expected to work?',\n",
       "  'What are the consequences for excessive absenteeism at KJR?']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    \"How much leave to KJR employees get?\",\n",
    "    \"What hours are KJR employees expected to work?\"\n",
    "]\n",
    "\n",
    "fewshot_test_set = test.generate_test_set(test_breadth = 3, test_depth = 2, examples = examples)\n",
    "fewshot_test_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
