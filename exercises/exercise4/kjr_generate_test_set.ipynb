{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Test Set with TruLens\n",
    "\n",
    "In the early stages of developing an LLM app, it is often challenging to generate a comprehensive test set on which to evaluate your app.\n",
    "\n",
    "This notebook demonstrates the usage of test set generation using TruLens, particularly targeted at applications that leverage private data or context such as RAGs.\n",
    "\n",
    "By providing your LLM app callable, we can leverage your app to generate its own test set dependant on your specifications for `test_breadth` and `test_depth`. The resulting test set will both question categories tailored to your data, and a list of test prompts for each category. You can specify both the number of categories (`test_breadth`) and number of prompts for each category (`test_depth`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.generate_test_set import GenerateTestSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from LangChain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load example content from the web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"KJR-Policy-Manual-August-23.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "vectorstore = Chroma.from_documents(documents=pages, embedding=OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a test set using the RAG\n",
    "\n",
    "Now that we've set up the application, we can instantiate the `GenerateTestSet` class with the application. This way the test set generation will be tailored to your app and data.\n",
    "\n",
    "After instantiating the `GenerateTestSet` class, generate your test set by specifying `test_breadth` and `test_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Standards of Conduct': ['What are the consequences for breaching the Code of Conduct at KJR?',\n",
       "  'How does KJR ensure that team members maintain the highest standards of honesty, integrity, and respect in their conduct?'],\n",
       " 'Compliance': ['What are the requirements for suppliers to notify KJR of any actual or suspected breaches of the Act?',\n",
       "  'Who is responsible for approving the annual compliance statement and how is it prepared in association with KJR?'],\n",
       " 'Professionalism': ['How does KJR expect team members to dress when working on-site or meeting with customers?',\n",
       "  'What are the consequences for team members who breach the KJR Code of Conduct regarding dress standards?'],\n",
       " 'Consequences': ['What are examples of misconduct that may result in disciplinary action, including termination of employment?',\n",
       "  'How does KJR determine whether misconduct is gross or serious, and what are the potential consequences for employees in those cases?'],\n",
       " 'Unacceptable Use': ['What types of content are considered unacceptable for viewing, downloading, or uploading using KJR supplied equipment?',\n",
       "  'How should team members handle the discovery of disparaging material about KJR online?']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = GenerateTestSet(app_callable = rag_chain.invoke)\n",
    "test_set = test.generate_test_set(test_breadth = 5, test_depth = 2)\n",
    "test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standards of Conduct\n",
      "Compliance\n",
      "Professionalism\n",
      "Consequences\n",
      "Unacceptable Use\n"
     ]
    }
   ],
   "source": [
    "for category in test_set:\n",
    "        print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Standards of Conduct\": [\n",
      "        \"What are the consequences for breaching the Code of Conduct at KJR?\",\n",
      "        \"How does KJR ensure that team members maintain the highest standards of honesty, integrity, and respect in their conduct?\"\n",
      "    ],\n",
      "    \"Compliance\": [\n",
      "        \"What are the requirements for suppliers to notify KJR of any actual or suspected breaches of the Act?\",\n",
      "        \"Who is responsible for approving the annual compliance statement and how is it prepared in association with KJR?\"\n",
      "    ],\n",
      "    \"Professionalism\": [\n",
      "        \"How does KJR expect team members to dress when working on-site or meeting with customers?\",\n",
      "        \"What are the consequences for team members who breach the KJR Code of Conduct regarding dress standards?\"\n",
      "    ],\n",
      "    \"Consequences\": [\n",
      "        \"What are examples of misconduct that may result in disciplinary action, including termination of employment?\",\n",
      "        \"How does KJR determine whether misconduct is gross or serious, and what are the potential consequences for employees in those cases?\"\n",
      "    ],\n",
      "    \"Unacceptable Use\": [\n",
      "        \"What types of content are considered unacceptable for viewing, downloading, or uploading using KJR supplied equipment?\",\n",
      "        \"How should team members handle the discovery of disparaging material about KJR online?\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(test_set, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"generated_prompts\"\n",
    "groundtruth_prompts = []\n",
    "for category in test_set:\n",
    "    for i in test_set[category]:\n",
    "        string = '{\"input\": \"' + i + '\", \"expected_output\": null}'\n",
    "        new_data = json.loads(string)\n",
    "        groundtruth_prompts.append(new_data)\n",
    "\n",
    "with open(filename + '.json', \"w\") as outfile:\n",
    "    outfile.write(json.dumps(groundtruth_prompts, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide a list of examples to help guide our app to the types of questions we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Professionalism': ['How many days of annual leave do KJR team members accrue per completed year of service?',\n",
       "  'What is the basic entitlement for personal leave for full-time KJR team members?'],\n",
       " 'confidentiality': ['What are the consequences for excessive absenteeism or tardiness at KJR?',\n",
       "  'Is it possible for a complainant or witness to remain anonymous in a complaint or investigation at KJR?'],\n",
       " 'social media': ['How many hours are KJR employees expected to work?',\n",
       "  'What are the consequences for excessive absenteeism at KJR?']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    \"How much leave to KJR employees get?\",\n",
    "    \"What hours are KJR employees expected to work?\"\n",
    "]\n",
    "\n",
    "fewshot_test_set = test.generate_test_set(test_breadth = 3, test_depth = 2, examples = examples)\n",
    "fewshot_test_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens18_release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
